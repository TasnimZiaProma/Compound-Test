{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import skimage.io as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Data = pd.read_csv(\"./CMATERdbTrain.csv\", usecols=[\"labels\",\"directory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset\\CMATERdbTrain\\1\\bcc000000.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset\\CMATERdbTrain\\1\\bcc000032.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset\\CMATERdbTrain\\1\\bcc000033.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset\\CMATERdbTrain\\1\\bcc000034.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset\\CMATERdbTrain\\1\\bcc000035.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>156</td>\n",
       "      <td>dataset\\CMATERdbTrain\\156\\bcc001573.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>156</td>\n",
       "      <td>dataset\\CMATERdbTrain\\156\\bcc001574.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>156</td>\n",
       "      <td>dataset\\CMATERdbTrain\\156\\bcc001572.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>158</td>\n",
       "      <td>dataset\\CMATERdbTrain\\158\\bcc001575.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>159</td>\n",
       "      <td>dataset\\CMATERdbTrain\\159\\bcc001576.bmp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1577 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels                                directory\n",
       "0          1    dataset\\CMATERdbTrain\\1\\bcc000000.bmp\n",
       "1          1    dataset\\CMATERdbTrain\\1\\bcc000032.bmp\n",
       "2          1    dataset\\CMATERdbTrain\\1\\bcc000033.bmp\n",
       "3          1    dataset\\CMATERdbTrain\\1\\bcc000034.bmp\n",
       "4          1    dataset\\CMATERdbTrain\\1\\bcc000035.bmp\n",
       "...      ...                                      ...\n",
       "1572     156  dataset\\CMATERdbTrain\\156\\bcc001573.bmp\n",
       "1573     156  dataset\\CMATERdbTrain\\156\\bcc001574.bmp\n",
       "1574     156  dataset\\CMATERdbTrain\\156\\bcc001572.bmp\n",
       "1575     158  dataset\\CMATERdbTrain\\158\\bcc001575.bmp\n",
       "1576     159  dataset\\CMATERdbTrain\\159\\bcc001576.bmp\n",
       "\n",
       "[1577 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Data = pd.read_csv(\"./CMATERdbTest.csv\", usecols=[\"labels\",\"directory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>directory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset\\CMATERdbTest\\1\\bcc000000.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset\\CMATERdbTest\\1\\bcc000014.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset\\CMATERdbTest\\1\\bcc000012.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset\\CMATERdbTest\\1\\bcc000011.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>dataset\\CMATERdbTest\\1\\bcc000010.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>155</td>\n",
       "      <td>dataset\\CMATERdbTest\\155\\bcc000467.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>156</td>\n",
       "      <td>dataset\\CMATERdbTest\\156\\bcc000468.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>158</td>\n",
       "      <td>dataset\\CMATERdbTest\\158\\bcc000469.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>159</td>\n",
       "      <td>dataset\\CMATERdbTest\\159\\bcc000470.bmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>166</td>\n",
       "      <td>dataset\\CMATERdbTest\\166\\bcc000471.bmp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>472 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     labels                               directory\n",
       "0         1    dataset\\CMATERdbTest\\1\\bcc000000.bmp\n",
       "1         1    dataset\\CMATERdbTest\\1\\bcc000014.bmp\n",
       "2         1    dataset\\CMATERdbTest\\1\\bcc000012.bmp\n",
       "3         1    dataset\\CMATERdbTest\\1\\bcc000011.bmp\n",
       "4         1    dataset\\CMATERdbTest\\1\\bcc000010.bmp\n",
       "..      ...                                     ...\n",
       "467     155  dataset\\CMATERdbTest\\155\\bcc000467.bmp\n",
       "468     156  dataset\\CMATERdbTest\\156\\bcc000468.bmp\n",
       "469     158  dataset\\CMATERdbTest\\158\\bcc000469.bmp\n",
       "470     159  dataset\\CMATERdbTest\\159\\bcc000470.bmp\n",
       "471     166  dataset\\CMATERdbTest\\166\\bcc000471.bmp\n",
       "\n",
       "[472 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "472\n"
     ]
    }
   ],
   "source": [
    "nuTest = Test_Data.to_numpy()\n",
    "print(len(nuTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset\\\\CMATERdbTest\\\\1\\\\bcc000000.bmp'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Data.to_numpy()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = sk.imread(Test_Data.to_numpy()[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 109, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 149, 109])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_image = t(image)\n",
    "t_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_image = torch.from_numpy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([149, 109, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nexts = torch_image.permute(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 149, 109])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nexts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompundCharacterDataset(Dataset):\n",
    "    def __init__(self, csv_dir_path,  transforms=None):\n",
    "        ### numpy array for entire dataset\n",
    "        self.dataset = pd.read_csv(csv_dir_path, usecols=[\"labels\",\"directory\"]).to_numpy()  \n",
    "        \n",
    "        ### labels\n",
    "        self.labels = self.dataset[:,0]\n",
    "        #print(self.labels)\n",
    "        ### images\n",
    "        self.images = self.dataset[:,1]\n",
    "        #print(self.images)\n",
    "        \n",
    "        ### transformations to apply on images\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        label = torch.tensor(self.labels[index])\n",
    "        image_dir = self.images[index]\n",
    "        #print(self.images)\n",
    "        image = sk.imread(os.path.join(os.getcwd(),image_dir))\n",
    "        image = resize(image, (100, 100, 3))\n",
    "        reshaped_image = image\n",
    "        if self.transforms:\n",
    "            reshaped_image = self.transforms(reshaped_image)\n",
    "        return reshaped_image,label \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATASET = CompundCharacterDataset(csv_dir_path=\"./CMATERdbTest.csv\",transforms=transforms.ToTensor())\n",
    "TEST_LOADER = DataLoader(dataset=TEST_DATASET, batch_size=BATCH_SIZE, shuffle= False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET = CompundCharacterDataset(csv_dir_path=\"./CMATERdbTrain.csv\",transforms=transforms.ToTensor())\n",
    "TRAIN_LOADER = DataLoader(dataset=TRAIN_DATASET, batch_size=BATCH_SIZE, shuffle= False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEST_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (4): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (5): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (6): ReLU(inplace=True)\n",
      "  (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=2500, out_features=159, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn_layers =  nn.Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "            # in_channels (int) – Number of channels in the input image. For B&W it is 1.\n",
    "            # out_channels (int) – Number of channels produced by the convolution. 4 filters\n",
    "            # kernel_size (int or tuple) – Size of the convolving kernel (3x3)\n",
    "            # stride (int or tuple, optional) – Stride of the convolution\n",
    "            # padding (int or tuple, optional) – Padding of 1 added to both sides of the input\n",
    "            # example x1 = (n, c=3 , h=100 , w=100 )\n",
    "            nn.Conv2d(3, 4, kernel_size=3, stride=1, padding=1), #in_channels = 1 is a data dependent hyperparameter. It is 1 because the images are in grayscale\n",
    "            # x2 = (n, c=12 , h=100 , w=100 )\n",
    "            nn.BatchNorm2d(4), # Normalize output from the activation function. \n",
    "            nn.ReLU(inplace=True), # negative elements to zero\n",
    "            # x2 = (n, c=12 , h=100 , w=100 )\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), #Stride is the number of pixels shifts over the input matrix. When the stride is 1 then we move the filters to 1 pixel at a time. When the stride is 2 then we move the filters to 2 pixels at a time and so on\n",
    "            # x3 = (n, c=12 , h=49 , w=49 )\n",
    "            # Defining another 2D convolution layer\n",
    "            nn.Conv2d(4, 4, kernel_size=3, stride=1, padding=1),\n",
    "            # x3 = (n, c=4 , h=49 , w=49 )\n",
    "            nn.BatchNorm2d(4), # 4 features\n",
    "            nn.ReLU(inplace=True), # inplace = True will modify the input directly, without allocating any additional output.\n",
    "            # x3 = (n, c=48 , h=49 , w=49 )\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # Downsamples the input representation by taking the maximum value\n",
    "            # x4 = (n, c=48 , h=25 , w=25 )\n",
    "        )\n",
    "        # outputSize = floor[(inputSize - filterSize + 2 * padding) / stride] + 1\n",
    "print(cnn_layers)\n",
    "\n",
    "\n",
    "linear_layers = nn.Sequential(\n",
    "            nn.Linear(4 * 25 * 25, 159) \n",
    "#159 classes are available for the compound classes dataset. It is a data dependent hyperparameter\n",
    ")\n",
    "\n",
    "print(linear_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.cnn_layer = cnn_layers\n",
    "        self.linear_layer = linear_layers\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layer(x)\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = self.linear_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda is available\n"
     ]
    }
   ],
   "source": [
    "optimizer =  optim.Adam(net.parameters(), lr=0.07) # learning rate \n",
    "# defining the loss function\n",
    "criterion =  nn.CrossEntropyLoss()\n",
    "# change loss function \n",
    "# 1. cross entropy \n",
    "# 2. 1 / (1 + distance between winning prob and second best prob)\n",
    "# add 1 and 2 \n",
    "# checking if GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    print('cuda is available')\n",
    "    net = net.cuda()\n",
    "    criterion = criterion.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_finder(predictions , labels):\n",
    "    softmax = torch.nn.Softmax(dim=1) \n",
    "    predictions = softmax(predictions)\n",
    "    values, max_indices = torch.max(predictions, dim=1) \n",
    "    accuracy = ( max_indices == labels ).sum().item()/max_indices.size()[0]\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs:int , withCustomLoss = False):\n",
    "    all_training_losses = []\n",
    "    all_training_acc = []\n",
    "    all_validation_losses = []\n",
    "    all_validation_acc = []\n",
    "    min_loss_at_epoch = -1\n",
    "    global_min_average_loss = torch.tensor(999999999)\n",
    "    # min average training loss = infinity \n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        targets = []\n",
    "        total_loss_epoch = 0\n",
    "        total_acc_epoch = 0\n",
    "        batches_traversed = 0 \n",
    "        for i, data in enumerate(TRAIN_LOADER, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.float() \n",
    "            if torch.cuda.is_available():\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            targets.append(labels)\n",
    "            total_loss_epoch = total_loss_epoch + loss.item()\n",
    "            training_accuracy = accuracy_finder(predictions=outputs, labels=labels)\n",
    "            total_acc_epoch = total_acc_epoch + training_accuracy\n",
    "            batches_traversed = batches_traversed + 1 \n",
    "        all_training_losses.append(total_loss_epoch/batches_traversed)\n",
    "        all_training_acc.append(total_acc_epoch/batches_traversed)\n",
    "        val_loss, val_acc = validate()\n",
    "        all_validation_losses.append(val_loss)\n",
    "        all_validation_acc.append(val_acc)\n",
    "        print(\"epoch : {}, training loss : {}, training accuracy {},  validation loss : {}, validation accuracy {}\".format(epoch+1,round((total_loss_epoch/batches_traversed),3),round((total_acc_epoch/batches_traversed),3), round(val_loss,3), round(val_acc,3)))\n",
    "        #save the model with minimum training loss\n",
    "        avg_training_loss_per_epoch = total_loss_epoch/batches_traversed\n",
    "        # if min average training loss > avg_training_loss : min average training loss = avg_training_loss\n",
    "        if global_min_average_loss > avg_training_loss_per_epoch:\n",
    "            global_min_average_loss = avg_training_loss_per_epoch\n",
    "            if withCustomLoss == True : \n",
    "                torch.save(net.state_dict(), \"./custom_loss_model.pth\")\n",
    "            else:\n",
    "                torch.save(net.state_dict(), \"./loss_model.pth\")\n",
    "            min_loss_at_epoch = epoch\n",
    "        # save the model \n",
    "        \n",
    "    print('Finished Training')\n",
    "    return (all_training_losses, all_training_acc, all_validation_losses, all_validation_acc, min_loss_at_epoch, global_min_average_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-e77debcbbb89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtraining_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_loss_at_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_avg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-37-8467afdfe6c3>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epochs, withCustomLoss)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;31m# zero the parameter gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "training_loss, training_acc, val_loss, val_acc, min_loss_at_epoch, min_avg_loss = train(epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
